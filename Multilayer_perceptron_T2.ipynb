{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Salvadorglezf/Classic-deep-learning-exercises/blob/main/Multilayer_perceptron_T2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tarea 1 Red neuronal Perceptrón multicapa  en Tensorflow 2\n",
        "\n",
        "#Gonzalez Flores Jesus Salvador\n",
        "\n",
        "Se implemento el mismo clasificador de prendas de ropa usando el conjunto de datos MNIST fashion. EL objetivo de esta implementación es comparar el proceso entre TF1 y TF2.\n"
      ],
      "metadata": {
        "id": "djuuiW4gEoYE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uc_1rMLDHqpB"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wbM3u15dHyLO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YLPdd09_I6Fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df87efab-50d5-4ccc-a3b5-f8258a559d1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets.fashion_mnist import load_data\n",
        "fashion_mnist = load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "A-CoNFwFI72A"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test)=fashion_mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDt8o9nUJA1_",
        "outputId": "820bbe3c-edec-43f9-c16e-3ee4793fce3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "t-aW7yoOJC2f"
      },
      "outputs": [],
      "source": [
        "imagendemo=x_train[0,:,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "x0c3LDsXJHH6",
        "outputId": "cccbbf72-2445-4739-bcf3-6a4aaee2bef5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe0bbbdc0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(imagendemo,cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4ry0H9PJJVSP"
      },
      "outputs": [],
      "source": [
        "# Define classes\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egULKQvRJ0IU",
        "outputId": "78dd8adb-4594-4263-fb2b-f081fbededa7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "x_train = x_train.reshape(-1,28*28).astype('float32')\n",
        "x_test = x_test.reshape(-1,28*28).astype('float32')\n",
        "\n",
        "\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "x_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Codificación one hot"
      ],
      "metadata": {
        "id": "9XbGHA5eUV3k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se hace uso de la función one hot encoder de scikit kearn para codificar las etiquetas de los datos."
      ],
      "metadata": {
        "id": "M5AwtdKLE9Es"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaMwU0tSJ7gR",
        "outputId": "d17fd12e-d46c-48ce-8beb-70b05627fedf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# onehot encode\n",
        "\n",
        "#En TF2 tampoco tenemos las funciones para codificar en One hot las etiquetas de\n",
        "#los datos. Por eso, usamos las funciones de SKLearn que importamos \n",
        "#Cargamos la función en onehot_encoder\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "#Le damos forma a nuestro y_train\n",
        "#La forma es (numero de datos, etiqueta categorica)\n",
        "y_train = y_train.reshape(len(y_train), 1)\n",
        "#Las cambiamos a un vector one-hot\n",
        "y_train_onehot = onehot_encoder.fit_transform(y_train)\n",
        "\n",
        "y_test = y_test.reshape(len(y_test), 1)\n",
        "y_test_onehot = onehot_encoder.fit_transform(y_test)\n",
        "\n",
        "y_train_onehot.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definición de la arquitectura\n",
        "\n",
        "TF2 nos permite manejar como objetos la arquitectura de la red. Dentro de la definición de la arquitectura se decisión una red con 200 nodos y tan solo 2 capas ocultas. Los pesos de cada capa fueron regularizados multiplicados directamente por 0.1 para evitar que los valores numéricos sean demasiado grandes, si se usaban valores más grandes el modelo no superaba una precisión del 80%. Se mantuvo la función de activación Relu y el optimizador ADAM con un learning rate de 0.001 para las métricas de precisión se uso una precisión simple y para la función de perdida se mantuvo la función softmax cross entripy with logits y se usó una métrica de promedios."
      ],
      "metadata": {
        "id": "JgPPKsAIFJRW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "M-s9HgINKDP5"
      },
      "outputs": [],
      "source": [
        "#Aqui notamos el primer cambio entre TF1 y TF2.\n",
        "#En TF1 usabamos una función para declarar la arquitectura de nuestra DNN, pero \n",
        "#en TF2 necesitamos hacer un objeto (cambiamos de paradigma estructurado a paradigma orientado a objetos)\n",
        "\n",
        "class DNN_model(object):\n",
        "  #Este es el inicializador del objeto, cuando decalaramos un objeto de la clase DNN_model\n",
        "  #adquiere todo aquello dentro del __init__\n",
        "  def __init__(self,\n",
        "               n_nodes_hl1=200,\n",
        "               n_nodes_hl2=200,\n",
        "               n_nodes_hl3=200,\n",
        "               n_nodes_hl4=200,\n",
        "               n_classes=10):\n",
        "    #Cada capa de la red, sus pesos y bias, se vuelven un atributo del objeto\n",
        "    #Ya no tenemos los diccionario de las capas\n",
        "    #Todos los parametros siguen siendo tf.Variable\n",
        "    #En TF2 tampoco tenemos los generadores de números aleatorios, por eso, necesitamos\n",
        "    #utilizar los aleatorios de numpy.\n",
        "    #Además de eso, tenemos que agregarle un nombre a cada parte de la capa \"hl1weigths\", \"hl1bias\", etc\n",
        "    #También, le agregamos el tipo de dato a cada capa. En TF2 el más adecuado es el float32\n",
        "    self.h1LW = tf.Variable(0.1*np.random.rand(784, n_nodes_hl1),name=\"hl1weigths\",dtype=\"float32\")\n",
        "    self.h1LB = tf.Variable(0.1*np.random.rand(n_nodes_hl1),name=\"hl1bias\",dtype=\"float32\")\n",
        "    self.h2LW = tf.Variable(0.1*np.random.rand(n_nodes_hl1, n_nodes_hl2),name=\"hl2weigths\",dtype=\"float32\")\n",
        "    self.h2LB = tf.Variable(0.1*np.random.rand(n_nodes_hl2),name=\"hl2bias\",dtype=\"float32\")\n",
        "    self.h3LW = tf.Variable(0.1*np.random.rand(n_nodes_hl2, n_nodes_hl3),name=\"hl3weigths\",dtype=\"float32\")\n",
        "    self.h3LB = tf.Variable(0.1*np.random.rand(n_nodes_hl3),name=\"hl3bias\",dtype=\"float32\")\n",
        "    self.h4LW = tf.Variable(0.1*np.random.rand(n_nodes_hl3, n_nodes_hl4),name=\"hl4weigths\",dtype=\"float32\")\n",
        "    self.h4LB = tf.Variable(0.1*np.random.rand(n_nodes_hl4),name=\"hl4bias\",dtype=\"float32\")\n",
        "    self.outW = tf.Variable(0.1*np.random.rand(n_nodes_hl4, n_classes),name=\"outweigths\",dtype=\"float32\")\n",
        "    self.outB = tf.Variable(0.1*np.random.rand(n_classes),name=\"outbias\",dtype=\"float32\")\n",
        "\n",
        "    #Finalmente, además de la decalaración de los pesos y bias de las capas, tenemos que inidcar qué atributos del objeto\n",
        "    #son entrenables. \n",
        "    #Esto permite declarar partes que sí se entrenan y partes que no. Esto sucede porque TF2 esta un poco en más bajo nivel\n",
        "    #que TF1. Estos son los elementos que ajustara el optimizador\n",
        "    self.trainable_variables =[self.h1LW,self.h1LB,self.h2LW,self.h2LB,self.h3LW,self.h3LB,self.h4LW ,self.h4LB,self.outW,self.outB]          \n",
        "  \n",
        "  def __call__(self,x): \n",
        "      # Declarando la arquitectura\n",
        "\n",
        "      #Cuando se genera un objeto, podemos mandar a llamar sus operaciones\n",
        "      #Para nuestra DNN lo que queremos es hacer es la propagación hacia adelante\n",
        "\n",
        "      #Las operaciones siguen siendo las de TF1, hacemos X*W+B\n",
        "      l1 = tf.add(tf.matmul(x,self.h1LW), self.h1LB)\n",
        "      #aplicamos la función de activación/transferencia\n",
        "      l1 = tf.nn.relu(l1)\n",
        "\n",
        "      l2 = tf.add(tf.matmul(l1,self.h2LW), self.h2LB)\n",
        "      l2 = tf.nn.relu(l2)\n",
        "\n",
        "      l3 = tf.add(tf.matmul(l2,self.h3LW), self.h3LB)\n",
        "      l3 = tf.nn.relu(l3)   \n",
        "\n",
        "      l4 = tf.add(tf.matmul(l3,self.h4LW), self.h4LB)\n",
        "      l4 = tf.nn.relu(l4)   \n",
        "\n",
        "      output = tf.matmul(l4,self.outW) + self.outB\n",
        "      return output\n",
        "      #Cada vez que mandemos a llamar a la red se ejecuta la propagación hacia adelante\n",
        "\n",
        "      #TF2 nos permite separar entre el modelo y las funciones propias del entrenamiento\n",
        "      #como el cálculo del costo y la optimización de parámetros\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OSxSzHR9KLhO"
      },
      "outputs": [],
      "source": [
        "#Hacemos un objeto de la clase DNN_model\n",
        "DNN = DNN_model()\n",
        "#Mandamos a llamar la propagación hacia adelante del objeto DNN\n",
        "#Nuestro objeto es una especie de función, cuando lo mandamos a llamar se ejecuta el \"predict\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BXzIljlsLYch"
      },
      "outputs": [],
      "source": [
        "optimizador = tf.compat.v1.train.AdamOptimizer(learning_rate=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UGz9P7UoLbi4"
      },
      "outputs": [],
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "#Aqui esta la exactitud\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "67qNac1LLqA6"
      },
      "outputs": [],
      "source": [
        "#Declaramos el paso de entrenamiento\n",
        "\n",
        "def train_step(model,tdata, labels):\n",
        "  #Esta funcion recibe el modelo, los datos de entrenamiento y sus etiquetas\n",
        "  with tf.GradientTape() as tape:\n",
        "    #Cargamos el calculo de gradiente de tensorflow y lo renombramos como tape (la cinta del gradiente)\n",
        "    #Todo lo que esta dentro de este encabezado se va a ocupar para el calculo del gradiente\n",
        "    #Hacemos la propagacion hacia delante de los datos de entrenamiento\n",
        "    predictions = model(tdata)\n",
        "    #calculo de una funcion de error \n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels, predictions))\n",
        "    #Aqui estamos usando la funcion de error que usamos en la red vanilla de TF1 y le indicamos\n",
        "    #que se calcula con la diferencia entre la prediccion y la etiqueta\n",
        "\n",
        "  #Ahora, declaramos las operaciones de optimización con nuestra cinta\n",
        "  #Este paso era oscuro en TF1, en TF2 se vuelve transparente \n",
        "\n",
        "  #Se calcula el gradiente como una funcion de la cinta, usando el error y los parametros entrenables del error\n",
        "  #Aqui le decimos qué se deriva y con respecto a qué, es decir, la perdida con respecto a los pesos y bias\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  #Esto nos da una versatilidad para calcular diferentes gradientes y derivarlos con respecto a datos especificos\n",
        "\n",
        "  #Ahora, necesitamos ordenar la información antes de pasarla por el optimizador\n",
        "  #Necesitamos hacer una lista con tuplas: (gradiente, variable) - > [(gradW1, W1),...,(gradWn, Wn)]\n",
        "  capped_grads_and_vars = [(grad,model.trainable_variables[index]) for index, grad in enumerate(gradients)]\n",
        "  #Ya con los gradientes y variables ordenados, ejecutamos el optimizador que elegimos\n",
        "  #optimizador.apply_gradients(zip(gradients,model.trainable_variables))\n",
        "  optimizador.apply_gradients(capped_grads_and_vars)\n",
        "  #Se ajustaron los pesos y bias\n",
        "  #Aqui mandamos a llamar las metricas que declaramos\n",
        "  #Estas funciones de error y accuracy nos sirven para desplegar el error acumulado\n",
        "  #y la exactitud de la epoca\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2id1ga6aL6cU"
      },
      "outputs": [],
      "source": [
        " #Este cabezal indica que el codigo es compilado, no interpetado\n",
        "#Esta es la funcion de prueba, para propagar sin modificar los datos\n",
        "def test_step(model,tdata, labels):\n",
        "  predictions = model(tdata)\n",
        "  t_loss =  tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels, predictions))\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "K5pq_fX8xRp_"
      },
      "outputs": [],
      "source": [
        "dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definición función de entrenamiento"
      ],
      "metadata": {
        "id": "5jPIaKPoUi4d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YNb1J4dwMBov"
      },
      "outputs": [],
      "source": [
        "_#En esta funcion hacemos el entrenamiento de la DNN\n",
        "def fitting(model,train_x,train_y,test_x,test_y,EPOCHS,N_batch,batch_size):\n",
        "  #Cargamos, el modelo, los datos de entrenamiento y prueba, el número de épocas\n",
        "  #el numero de lotes a usar y el tamaño de éstos (N_batch*batch_size) == len(dataset)\n",
        "\n",
        "   #Hacemos el ciclo de épocas\n",
        "  for epoch in range(EPOCHS):\n",
        "    i=0\n",
        "\n",
        "    while i+batch_size < len(train_x):\n",
        "    #  #Aqui ya no tenemos las funciones para separar los dataset por lotes\n",
        "    #  #Necesitamos separar los lotes a mano\n",
        "      start = i\n",
        "      end = i+batch_size\n",
        "    #  #Hacemos las rebanadas del tamaño del lote a usar\n",
        "      batch_x = train_x[start:end]\n",
        "      batch_y = train_y[start:end]\n",
        "    #Ejecutamos el paso de entrenamiento\n",
        "      train_step(model,batch_x,batch_y)\n",
        "      i+=batch_size\n",
        "     \n",
        "    test_step(model,test_x,test_y)\n",
        "    template = 'Epoch {}, Perdida: {}, Exactitud: {}, Perdida de prueba: {}, Exactitud de prueba: {}'\n",
        "    print(template.format(epoch+1,\n",
        "                         train_loss.result(),\n",
        "                        train_accuracy.result()*100,\n",
        "                        test_loss.result(),\n",
        "                        test_accuracy.result()*100))\n",
        "    \n",
        "    #Al finalizar la epoca, reiniciamos los errores y exactitudes para que no se acumulen con el anterior\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "\n",
        "  #En TF2 ya no usamos el diccionario de la red, el cual era uno de los puntos\n",
        "  #que mayor confusion generaban\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para entrenar el modelo se determinaron 18 épocas, 600 lotes con 100 muestras cada uno. Se noto que la precisión es dependiente del tamaño de lotes, pero si los lotes son demasiado grandes el entrenamiento tarda mas tiempo. Entonces se usaron lotes pequeños y un numero de épocas reducido."
      ],
      "metadata": {
        "id": "TY8AD_3uUgO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento"
      ],
      "metadata": {
        "id": "KOc6KHWHUuPS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vejZlHbcMDwO",
        "outputId": "9eeb42e6-3d2e-4f90-b3d6-47ca0c2373d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Perdida: 115.8009033203125, Exactitud: 11.238731384277344, Perdida de prueba: 2.473464250564575, Exactitud de prueba: 10.380000114440918\n",
            "Epoch 2, Perdida: 2.3757667541503906, Exactitud: 15.634390830993652, Perdida de prueba: 2.2096025943756104, Exactitud de prueba: 17.43000030517578\n",
            "Epoch 3, Perdida: 2.050739049911499, Exactitud: 26.12854766845703, Perdida de prueba: 1.6955230236053467, Exactitud de prueba: 35.88999938964844\n",
            "Epoch 4, Perdida: 1.3807839155197144, Exactitud: 48.87145233154297, Perdida de prueba: 1.1190603971481323, Exactitud de prueba: 57.400001525878906\n",
            "Epoch 5, Perdida: 0.9887275695800781, Exactitud: 64.07678985595703, Perdida de prueba: 0.8863478302955627, Exactitud de prueba: 69.8499984741211\n",
            "Epoch 6, Perdida: 0.8004429340362549, Exactitud: 71.78797912597656, Perdida de prueba: 0.7425963878631592, Exactitud de prueba: 75.08000183105469\n",
            "Epoch 7, Perdida: 0.6781839728355408, Exactitud: 76.22036743164062, Perdida de prueba: 0.6625884771347046, Exactitud de prueba: 77.13999938964844\n",
            "Epoch 8, Perdida: 0.6079303026199341, Exactitud: 78.50250244140625, Perdida de prueba: 0.6123205423355103, Exactitud de prueba: 78.56999969482422\n",
            "Epoch 9, Perdida: 0.5563910603523254, Exactitud: 80.52086639404297, Perdida de prueba: 0.5583828091621399, Exactitud de prueba: 80.37999725341797\n",
            "Epoch 10, Perdida: 0.510098934173584, Exactitud: 82.14022827148438, Perdida de prueba: 0.5231927037239075, Exactitud de prueba: 81.44000244140625\n",
            "Epoch 11, Perdida: 0.46971336007118225, Exactitud: 83.44741821289062, Perdida de prueba: 0.4994397461414337, Exactitud de prueba: 82.56999969482422\n",
            "Epoch 12, Perdida: 0.43817123770713806, Exactitud: 84.47746276855469, Perdida de prueba: 0.4810616672039032, Exactitud de prueba: 83.22000122070312\n",
            "Epoch 13, Perdida: 0.41162195801734924, Exactitud: 85.32220458984375, Perdida de prueba: 0.4611567258834839, Exactitud de prueba: 83.80000305175781\n",
            "Epoch 14, Perdida: 0.38865604996681213, Exactitud: 86.0317153930664, Perdida de prueba: 0.43932992219924927, Exactitud de prueba: 84.68000030517578\n",
            "Epoch 15, Perdida: 0.3669218420982361, Exactitud: 86.69115447998047, Perdida de prueba: 0.41897499561309814, Exactitud de prueba: 85.0199966430664\n",
            "Epoch 16, Perdida: 0.3474010229110718, Exactitud: 87.3205337524414, Perdida de prueba: 0.39892688393592834, Exactitud de prueba: 85.70999908447266\n",
            "Epoch 17, Perdida: 0.3292912542819977, Exactitud: 88.0267105102539, Perdida de prueba: 0.37540367245674133, Exactitud de prueba: 86.65999603271484\n",
            "Epoch 18, Perdida: 0.3139994144439697, Exactitud: 88.49415588378906, Perdida de prueba: 0.36730054020881653, Exactitud de prueba: 86.70999908447266\n"
          ]
        }
      ],
      "source": [
        "fitting(DNN,x_train,y_train_onehot,x_test,y_test_onehot,18,600,100) #EPOCHS,N_batch,batch_size"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Entrenamiento \n",
        "Como conclusión, TF2 nos permite manipular los parámetros de nuestros modelos de forma numérica, esto me permitió definir un modelo más preciso y mas rápido de entrenar. Pude confirmar la dependencia de la profundidad de la red y el impacto del número de lotes en el desempeño de la red."
      ],
      "metadata": {
        "id": "PKfke3VuUryZ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Multilayer perceptron T2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}